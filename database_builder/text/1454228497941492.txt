
  
    
      The 6th IEEE International Conference on Wireless, Mobile, and Ubiquitous Technologies in Education
    
    
      Development of Web-based Japanese Mimicry and Onomatopoeia Learning 
      Assistant System with Sensor Network 
    
    
      Bin Hou, Hiroaki Ogata, Masayuki Miyata, Mengmeng Li, Yoneo Yano 
      Dept. of Information Science and Intelligent Systems 
      The University of Tokushima 
      Tokushima, Japan 
      houbin2008@is.tokushima-u.ac.jp 
    
    
      Abstract- In this paper, we propose a web-based Japanese 
      mimicry 
      and 
      onomatopoeia 
      learning 
      assistant 
      system 
      (JAMIOLAS). In our previous studies, we have proposed 
      context-aware language learning assistant systems that used 
      wearable sensor and sensor network respectively, and attended 
      good results. In order to use this learning model in broader area 
      and more general scene, we are trying to realize the system on 
      website, and using on-line information as sensor data from 
      global sensor network. Besides, in order to support more words, 
      we are also using on-line multimedia such as video or picture to 
      create the context for learning. 
    
    
      language 
    
    
      Keywords-mimicry; 
      onomatopoeia; 
      sensor; 
      learning; context-aware learning; ubiquitous learning 
    
    
      I. 
       NTRODUCTIONI
      Context-aware computing [1] will help in the 
      organization and mediation of social interactions wherever 
      and whenever these contexts might occur [2]. Context-aware 
      computing makes it possible to learning foreign language 
      words related to people's feeling more comfortably. 
      Computer Supported Ubiquitous Learning (CSUL) has 
      integrated high mobility with embedded computing 
      environments [3,4]. We are focusing on applying CSUL to 
      language learning and are investigating computer supported 
      ubiquitous learning [4]. We proposed context-aware 
      language learning assistant system called JAMIOLAS [5-7] 
      for learning Japanese mimicry and onomatopoeia (MIO) 
      words. The previous two studies used wearable sensors and 
      sensor network respectively to detect the context 
      automatically and achieved certain effect. However, it still 
      cannot meet learner needs. Therefore, in this paper we 
      propose an improved system named JAMIOLAS 3.0 that can 
      support learning MIO by using sensor data. 
      IMICRY ND NOMATOPOEIA
      M A O
      II.
      JAPANESE 
      Mimicry words are imitating situations and body 
      movements while onomatopoeia shows sounds of something 
      [7]. Japanese is very rich in it. It is very important but very 
      •
      •
      difficult to learn because of following aspects: 
      Explanation: Nearly all of MIO words are just 
      feeling of Japanese. 
      Translation: Difficult to find the word that has the 
      exactly same meaning in other language. 
    
    
      Writing: Most of MIO words are written in hiragana 
      •
      or katakana (Japanese syllabify), not in kanji. It is 
      easy to pronounce but difficult to understand. 
      Hearing and Saying: The pronunciation of MIO 
      •
      usually has twice repetitions. It may cause the 
      illusion of hearing and judge the different words as 
      same one. 
      Meaning: MIO words have many synonyms and 
      •
      much assonance. 
      Situation: Some are only used in specific situation. 
      •
      For example, "jime jime" means muggy, dump and 
      humid, but it almost be used only in a rainy season. 
      Most of the MIO words are used to describe the speaker's 
      feeling. In order to know the speaker's feeling, we attempt to 
      acquire user's context with sensor. 
       1.0 A 2.0 ND 
      III. JAMIOLAS 
      JAMIOLAS 1.0 is implemented by wearable sensors 
      called Phidgets (physical widgets) [8] and a Tablet PC (HP 
      T1100) . When learning, the learner must wear Phidgets 
      connected to the system, and select a MIO as answer that is 
      most suitable for the situation in the question generated by 
      system. However, when learning, sometimes learners do not 
      know where he/she could learn the MIO. Learner must carry 
      the system when using it, so it is not so convenient. 
      JAMIOLAS 2.0 use the wireless sensor network instead 
      of wearable sensor, and use RFID to recognize user's 
      position. However, most of MIO words cannot be supported 
      by it, and it can only be used in limited area. For these issues, 
      we propose JAMIOLAS 3.0 to support learning MIO. 
       3.0 
      IV. JAMIOLAS 
      A. Context and sensor 
      There are three important aspect of context: Where you 
      are, who you are with, and what resources are nearby [9]. 
      Context includes not only user's location, but also the 
      lighting, noise level, social situation and so on [10]. Human 
      being usually gets the feeling from environment by five 
      senses including seeing, hearing, smelling, tasting and 
      touching. It is possible to get such context with sensors. The 
      context can be classified as two types - can be created by 
      computer (scene, sound) and cannot be created by computer 
      (weather). 
    
    
      117
    
    
      978-0-7695-3992-8/10 $26.00 ' 2010 IEEE
      DOI 10.1109/WMUTE.2010.24
    
  
  
    
      TABLE I. 
    
    
      ,
       RELATIONSHIP BETWEEN BODY SENSE CONTEXT AND 
      SENSOR
    
    
      Body Sense 
      Seeing 
    
    
      Hearing 
      Feeling 
    
    
      Context 
      Light 
      Scene 
      Sound 
      Temperature 
    
    
      Sensor 
      Light Sensor 
      Image Sensor 
      Sound Sensor 
      Temperature Sensor 
    
    
      (A)Quiz for context (B)Give a wrong answer 
    
    
      B. Implementation 
      Figure 1 shows the architecture of system. The weather 
      information and media files are learning stuff in this system. 
      We are using real-time on-line weather service as sensor 
      network. As the feeling is different one by one, the system 
      will use the voting mode to decide the proximate select to the 
      weather or media. We plan to use mobile as client, but for 
      limitation on condition, we have to implement this system on 
      web side at current. 
    
    
      (D)Word test 
       (C)Give a right answer 
      Figure 2. Student's interface 
    
    
      Figure 1. System architecture 
    
    
      C. System interface and function 
      1) Student's interface 
      This system mainly supports the following functions for 
      students. 
      Learning by weather information: There are two 
      •
      modes: Fix mode - system will show uses user's 
      default location, and generate a quiz to ask learner 
      how to describe the current weather with MIO; Tour 
      mode - learner must set the coordinate first. When 
      learner gave a right answer, he/she can view the 
      example and media for each selection or enter the 
      test mode to take a test. 
      Learning by media: Learner choose a media file and 
      •
      give select a MIO word that is most suitable for this 
      media. Finally there is a test function for learner 
      Learning in free mode: the free mode likes a media 
      •
      dictionary, user can look up a word and the result is 
      composed of examples and media. 
      Figure 2 shows a typical learning flow in this system. 
    
    
      2) Teacher's interface 
      The teacher can use all the functions available for 
      students. In addition, the teacher has access to another two 
      functions. 
      Evaluate weather/media: The teacher can vote a 
      •
      word for weather/media. There are some restrictions 
      for evaluation. The user who has the role of teacher 
      can only vote for the weather once within one hour 
      unless the weather information has been updated. 
      And each media file can only be voted for once by 
      each user. 
      Word management: The user who has the role of 
      •
      teacher can manage words. This function contains 
      the common CRUD (create, retrieve, update, delete), 
      word example management, and weather word 
      management. 
      VALUATION
      V. E
      A. Method 
      We have done an experiment to compare JAMIOALS 3.0 
      to traditional method. After voting by Japanese students, we 
      planned to prepare 10 words as test data in this experiment 
      (Table II). 6 Japanese learners took the part of student. In 
      them, 1 is living in Tokushima (Japan), 3 are living in Tokyo 
      (Japan) and 2 are living in Dalian (China). They were 
      divided into two groups: one used dictionary first, and 
      another used system. After 20 minutes, they exchanged, and 
      continue to learn for 20 minutes. We put pre-test, mid-test 
      and post-test in this experiment. Finally, they answered a 
      questionnaire that is 5 ranges from 1 to 5. 
    
    
      118
    
  
  
    
      TABLE II. 
    
    
       USED IN THE EXPERIMENTATION
      MIO
    
    
      Dictionary
      JAMIOLAS 3.0
    
    
      Context 
      MIO 
      Weather(Temperature) 
      hinyari, nuku nuku 
      Scene(Posture of walking) uro uro, tyoko tyoko, noshi noshi, yochi 
      yochi 
      Sound(Sound of animals) ka ka, ga ga, gero gero, tyun tyun 
    
    
      Figure 4. Total increased score on type 
    
    
      B. Result 
      We did three tests for each learner during the 
      experiments and administered a questionnaire. These 
      supplied us with our experimental data. Although this is an 
      initial experiment, with the analysis of the experimental data 
      we can see the following results. 
      1) The overall results 
      The following chart (Figure 3) shows the results of the 
      pre-test, mid-test and post-test. 
    
    
      Dictionary First
      Group
      System First
      Group
    
    
      Pre-test
    
    
      Post-test
    
    
      Mid-test
    
    
      Figure 3. Average increased score in the experiment 
    
    
      Figure 4 shows the increase in score for each type of 
      context. All three types were learned better by using the 
      system than by using the dictionary. It shows that words 
      related to sound (onomatopoeia) showed the highest increase 
      in score both by the dictionary and the system. For the 
      weather context, only the system provided benefit; in this 
      experiment, the dictionary had no effect on learning the 
      words related to weather. On the contrary, one learner 
      changed their original right answer into a wrong answer after 
      learning the weather words using the dictionary and got a 
      lower score. This suggests that the dictionary cannot 
      effectively explain MIO related to weather. 
      3) Questionnaire 
      Table III shows the results of the questionnaire. 
      According to Question (1), we learned that the system is 
      helpful for learning mimicry and onomatopoeia. The highest 
      average score and lowest standard deviation of Question (1) 
      in the questionnaire shows the system is generally 
      considered useful. Question (2) asked whether the answers of 
      the presented quiz were appropriate to the situation or not. In 
      this case the result was less satisfactory, it demonstrates the 
      biggest problem of learning MIO is with feelings, because by 
      the standard deviation we can see the feeling is different 
      depending upon the person. Therefore, in the future we 
      should seek for a method to make the words more 
      appropriate to the situation. 
    
    
      TABLE III. 
    
    
      RESULT OF QUESTIONNAIRE
    
    
      Question 
      Avg SD
      1 Were you able to learn mimicry and onomatopoeia by this 4.8 0.4
      system? 
      2 Was the answer of the presented quiz appropriate to the 3.8 0.8
      situation? 
      3 Were you able to learn mimicry and onomatopoeia with 4.2 0.8
      enjoyment? 
      4 Is the system easy to use? 
      4.2 0.8
      5 Do you want to learn by using this system in the future? 
      4.3 0.5
      6 Which do you think enhances learning more, this system or 4.5 0.5
      traditional learning? (this system: 5, traditional learning: 1) 
    
    
      Figure 3 shows the average score increases in the mid-
      test and post-test. As shown in this figure, the system first 
      group showed better increased score than the dictionary first 
      group. After the mid-test and the group changeover, the final 
      results from the system first group were higher than for the 
      dictionary first group. Although the data from this small 
      sample size would not bear statistical analysis, the results 
      suggest that JAMIOLAS 3.0 can be more effective than a 
      dictionary for learning MIO. 
      From feedback, we learned that when users in the system 
      first group used JAMIOLAS 3.0 from the beginning, both 
      the system and the words were new to them, and they made 
      full use of system. However, when users had first learned the 
      meaning of words from the dictionary, they lost the freshness 
      of the words, so they felt that they had already understood 
      the meaning and the system was underutilized. In the 
      questionnaire, most learners suggested we add the meanings 
      in the system, and the system should provide an explanation 
      when the results are shown. 
      2) Results on type of context 
      There were three types of context in the evaluation 
      experiment. We used the mid-test data to plot this in order to 
      see the effects of the systems for different types of context. 
    
    
      Results to Question (3) showed learners were able to 
      effectively learn using this system, which can motivate them 
      to learn language. For Question (4), most learners thought 
    
    
      119
    
  
  
    
      Using embedded mobile sensors to acquire sensor 
      • 
      data anywhere at any time. The current system is not 
      using sensors that we have deployed, but the sensor 
      data is received from the global sensor network that 
      is supplied by an on-line weather provider. In the 
      future, sensors will be embedded in each mobile, as 
      users' phones will know a lot about the world around 
      them [11,12]. Our future plan is to support Japanese 
      MIO learning with the sensors that have been 
      embedded in the next generation of mobile 
      technology, especially mobiles using the Android 
      operating system [13]. Android has already supplied 
      an API for 8 types of sensor including accelerometer, 
      gyroscope, light, magnetic field, orientation, 
      pressure, proximity and temperature sensors [14,15]. 
      Introducing biosensors to support learning MIO 
      •
      related to emotion. Because most MIO are just used 
      to describe one's feelings, there are many words 
      related to emotion, but these cannot be supported by 
      the current system. One way to recognize the 
      emotion is using biosensors to acquire information 
      from the human body [16]. 
      In addition, we must look for an approach to making the 
      questions in the system more appropriate to the learning 
      context. We should also consider how to introduce the 
      meaning of words into the system more effectively. 
      However, we will improve the system and conduct further 
      evaluations to gather more experimental data. 
    
    
      [1] G.D. Abowd and E.D. Mynatt, "Charting past, present, and future 
      research in ubiquitous computing," ACM Transactions on 
      Computer-Human Interaction (TOCHI), vol. 7, 2000, pp. 29-58. 
      [2] G. Fischer, "User Modeling in Human-Computer Interaction," 
      User Modeling and User-Adapted Interaction, vol. 11, 2001, pp. 
      65-86. 
      [3] Y.S. Chen, T.C. Kao, J.P. Sheu, and C.Y. Chiang, "A mobile 
      scaffolding-aid-based bird-watching learning system," 2002, pp. 
      15-22. 
      [4] H. Ogata and Y. Yano, "Context-aware support for computer-
      supported ubiquitous learning," 2004, pp. 27-34. 
      [5] M. Miyata, H. Ogata, T. Kondo, and Y. Yano, "JAMIOLAS 2.0: 
      Supporting to Learn Japanese Mimetic Words and Onomatopoeia 
      with Wireless Sensor Networks," Taipei: 2008, pp. 643-650. 
      [6] H. Ogata, T. Kondo, C. Yina, Y. Liub, and Y. Yanoa, "Computer 
      Supported Ubiquitous Learning Environment for Japanese 
      Mimicry and Onomatopoeia with Sensors," Supporting Learning 
      Flow Through Integrative Technologies, 2007, p. 463. 
      [7] H. Ogata, C. Yin, and Y. Yano, "JAMIOLAS: Supporting 
      Japanese Mimicry and Onomatopoeia Learning with Sensors," 
      2006, pp. 111-115. 
      [8] S. Greenberg and C. Fitchett, "Phidgets: easy development of 
      physical interfaces through physical widgets," ACM Press, 2001, 
      pp. 209-218. 
      [9] J. Lee, S. Oh, and M. Jeon, "A New Context-Aware Learning 
      System for Predicting Services to Users in Ubiquitous 
      Environment," International Symposium on Ubiquitous VR, 
      2007, p. 1. 
      [10] B. Schilit, N. Adams, and R. Want, "Context-aware computing 
      applications," Mobile Computing Systems and Applications, 
      1994. WMCSA'08. First Workshop on on Mobile Computing 
      Systems and Applications, Santa Cruz, CA, USA: 1994, pp. 85-
      90. 
    
    
      this system was easy to use. Question (3) and Question (4) 
      also have high standard deviations, and these tell us that we 
      must improve the interface of system and provide better 
      learning experience. Question (5) shows that users like using 
      this kind of system and would use it again. Question (6) 
      shows that compared to traditional learning; most learners 
      thought this system was more effective for learning MIO. 
      Apart from the above questions, we also asked for 
      feedback regarding the difficulties users encountered as they 
      were learning MIO. All of them said the words were difficult 
      to remember, but two of the users could not explain why. 
      Others said there are too many MIO words, and they could 
      not guess the meaning using the limited information. In 
      addition, although users had learned the meaning, because 
      they had no intuitive feeling and no environment, it was easy 
      to forget MIO words. These answers will help us to improve 
      the system in future work. We also asked the learners to 
      make some general comments on the system. One user said 
      this system was very interesting, they could easily learn the 
      meaning the words in an environment, and it is a really good 
      way to explain the MIO words by feeling. Most of users said 
      when the answer of a quiz is given, they could only see what 
      was right or wrong, but could not learn why. If the meaning 
      could be shown at that time, it will be more conducive to 
      remembering the words. One user said that in the test there 
      were sometimes too many questions for one word. This is in 
      fact a result of the current algorithm, which we can improve 
      in the future. Another user also said the video was not so 
      clear; however this problem cannot be solved at present 
      because of the limitation of technology. 
      During the evaluation, we learned that the system can 
      explain the words that related to feeling very well by sensor 
      data, and that learning efficacy and quality are better than 
      traditional learning. 
      VI. C ONCLUSION AND FUTURE WORK 
      In this paper, we described an improved context-aware 
      learning system named JAMIOLAS 3.0 that can support the 
      learning of Japanese MIO words in a sensory learning mode 
      with global sensor network. This is an on-line system that 
      can be used in a broader area than previous versions. It uses 
      on-line weather information as global weather sensor data. In 
      addition, it also uses media (video/audio) as image/sound 
      sensor data and can support learning more words than 
      before. Two methods are used in this system: created context 
      and detecting context automatically to provide the right MIO 
      for the learner's context. Through an initial evaluation 
      experiment, we can see that this system is effective for 
      learning MIO. The feeling related to a weather situation can 
      be explained by the system more effectively than by 
      dictionary. However, on the media side, although the media 
      can be explained by the system better than by the dictionary, 
      the results and feedback suggest that the dictionary is still 
      useful. With the help of the dictionary, a learner can learn the 
      words using both meaning and feeling. In the future, we will 
      focus on making the questions more appropriate to 
      environment and weather data, and we will also consider 
      how to use multiple conditions of weather information. 
      Our future research will be in the following directions: 
    
    
      120
    
  
  
    
      [15] A. Wright, "Get smart," Communications of the ACM, vol. 52, 
      2009, pp. 15-16. 
      [16] J.W.P. Ng, B.P.L. Lo, O. Wells, M. Sloman, C. Toumazou, N. 
      Peters, A. Darzi, and G.Z. Yang, "Ubiquitous monitoring 
      environment for wearable and implantable sensors (UbiMon)," 
      2004 
    
    
      [11] A. Rubin, "The future of mobile," Offical Google Blog, 2008. 
      [12] S. Poduri and G. Sukhatme, "Constrained coverage for mobile 
      sensor networks," IEEE; 1999, 2004, pp. 165-171. 
      [13] Kirby Chiang, Chi Cheng Chu, B. Prabhu, and R. Gadh, "In the 
      direction of a sensor mapping platform based on cellular phone 
      networks," Wireless Telecommunications Symposium, 2008. 
      WTS 2008, 2008, pp. 348-353. 
      [14] Google Projects for Android," Google Projects for Android, 
      2009. 
    
    
      121
    
  
